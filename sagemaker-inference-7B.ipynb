{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "252de0de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SageMaker fine tune ChatGLM\n",
    "\n",
    "#### 准备\n",
    "1. 升级boto3, sagemaker python sdk  \n",
    "2. 准备requirements.txt\n",
    "3. 准备s5cmd utility\n",
    "4. 下载HF model，并上传到S3(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f2c403",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.153.0-py2.py3-none-any.whl size=1008105 sha256=b5c59266f9d3f8b737aad3656323127b1d96ebc365d2213038e25c3985ac00cf\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/6a/0b/81/d7a0f0e734bc9f5ea74716acef6b397a6d473cb8e6b9b3f121\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: cloudpickle, sagemaker\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.2.0\n",
      "    Uninstalling cloudpickle-2.2.0:\n",
      "      Successfully uninstalled cloudpickle-2.2.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.146.0\n",
      "    Uninstalling sagemaker-2.146.0:\n",
      "      Successfully uninstalled sagemaker-2.146.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.11.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cloudpickle-2.2.1 sagemaker-2.153.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade boto3\n",
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9436071c-6e98-4b38-aff8-507193445382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 4176k  100 4176k    0     0  5928k      0 --:--:-- --:--:-- --:--:-- 11.9M\n"
     ]
    }
   ],
   "source": [
    "#print('s3://{}/llm/models/'.format(sagemaker_session.default_bucket()))\n",
    "#!aws s3 ls s3://sagemaker-us-west-2-687912291502/llm/models/\n",
    "!curl -L https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz | tar -xz && mv s5cmd ./ptuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a30f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\n",
      "sagemaker-us-west-2-687912291502\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffb9b61-51de-49ab-a21f-e462918b6920",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (3.6.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (4.4.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (4.63.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface_hub) (2022.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Installing collected packages: huggingface_hub\n",
      "Successfully installed huggingface_hub-0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30102f03-a5b5-42e4-9f87-76131cd3de1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013855934143066406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Fetching 21 files",
       "rate": null,
       "total": 21,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb00b6542394ebe8193648242d5f8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 21 files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005120038986206055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading ice_text.model",
       "rate": null,
       "total": 2706249,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adbf746d3d94dbda7e02c898d238c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ice_text.model:   0%|          | 0.00/2.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010117769241333008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)fa7e74/MODEL_LICENSE",
       "rate": null,
       "total": 2347,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6c78aa919b4a4d9aea65473ad7646d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fa7e74/MODEL_LICENSE:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015799760818481445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)a7e74/.gitattributes",
       "rate": null,
       "total": 1477,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7889120a96145d59c3a0081e1b810ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a7e74/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03249549865722656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)dcfa7e74/config.json",
       "rate": null,
       "total": 773,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b249f042aa18473395ee67874162f2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)dcfa7e74/config.json:   0%|          | 0.00/773 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011421680450439453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)/modeling_chatglm.py",
       "rate": null,
       "total": 57620,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77858351a95848f1898fc77803821ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/modeling_chatglm.py:   0%|          | 0.00/57.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03154349327087402,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)bd66dcfa7e74/LICENSE",
       "rate": null,
       "total": 11336,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3465747a1c8d4a15bf2f5dc719be35eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bd66dcfa7e74/LICENSE:   0%|          | 0.00/11.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0328061580657959,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)66dcfa7e74/README.md",
       "rate": null,
       "total": 5945,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc33e1cdce18443aa221f0740b01a5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)66dcfa7e74/README.md:   0%|          | 0.00/5.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.031374454498291016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)iguration_chatglm.py",
       "rate": null,
       "total": 4276,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9dbb7efcbd401482956d8a88011f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)iguration_chatglm.py:   0%|          | 0.00/4.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004847049713134766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00001-of-00008.bin",
       "rate": null,
       "total": 1740651802,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a7ced40b2141f09659660810483d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00008.bin:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011675596237182617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00008-of-00008.bin",
       "rate": null,
       "total": 1069286123,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fe321ad40c4baa86ad6554c2e45b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00008-of-00008.bin:   0%|          | 0.00/1.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03728818893432617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00005-of-00008.bin",
       "rate": null,
       "total": 1879722289,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a9e6fe2a294f55b9e70df58bbaac20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00005-of-00008.bin:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016272306442260742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00002-of-00008.bin",
       "rate": null,
       "total": 1879731432,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c817a78f3884c7ebc6c92a482a27402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00008.bin:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021346092224121094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00006-of-00008.bin",
       "rate": null,
       "total": 1879731496,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf44dcbcff24b9dbae01d121266db90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00006-of-00008.bin:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022115707397460938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00003-of-00008.bin",
       "rate": null,
       "total": 1980385902,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed17f050fb34b81a72d9e58685dba98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00003-of-00008.bin:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01946878433227539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00004-of-00008.bin",
       "rate": null,
       "total": 1913294120,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db027469d4246609b4af5756ed0db79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00004-of-00008.bin:   0%|          | 0.00/1.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02467489242553711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00007-of-00008.bin",
       "rate": null,
       "total": 1074103621,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d83b70251a41329af3bcee524baa2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00007-of-00008.bin:   0%|          | 0.00/1.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0070955753326416016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)model.bin.index.json",
       "rate": null,
       "total": 33416,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80bb8e49f3f4476289e6e2e47d5820e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007597684860229492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)7e74/quantization.py",
       "rate": null,
       "total": 15054,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9893b7215c5a45a6a48d9034860a04c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e74/quantization.py:   0%|          | 0.00/15.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007790803909301758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)_modeling_chatglm.py",
       "rate": null,
       "total": 13822,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad6443843b1417f905754b354549191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_modeling_chatglm.py:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010191917419433594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)enization_chatglm.py",
       "rate": null,
       "total": 17047,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbdd9f2962d413fb5790078ef704571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)enization_chatglm.py:   0%|          | 0.00/17.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009071111679077148,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)okenizer_config.json",
       "rate": null,
       "total": 441,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a95adbbed94957b67f5da830f2feab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_cache_path = Path(\"./model\")\n",
    "local_cache_path.mkdir(exist_ok=True)\n",
    "\n",
    "model_name = \"THUDM/chatglm-6b\"#\n",
    "\n",
    "# Only download pytorch checkpoint files\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.model\"]\n",
    "\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    cache_dir=local_cache_path,\n",
    "    #allow_patterns=allow_patterns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821416b3-e6d2-43a7-8553-c71b20df5aab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74\n",
      "s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/\n"
     ]
    }
   ],
   "source": [
    "print(model_download_path)\n",
    "model_uri=\"s3://\"+bucket+\"/llm/model/chatglm/orignal/\"\n",
    "print(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d2e7189-f340-49eb-983f-0d238fe7a99e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/tokenizer_config.json s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/tokenizer_config.json\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/quantization.py s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/quantization.py\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/configuration_chatglm.py s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/configuration_chatglm.py\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/README.md s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/README.md\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/LICENSE s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/LICENSE\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/pytorch_model.bin.index.json s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/pytorch_model.bin.index.json\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/test_modeling_chatglm.py s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/test_modeling_chatglm.py\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/modeling_chatglm.py s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/modeling_chatglm.py\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/MODEL_LICENSE s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/MODEL_LICENSE\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/config.json s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/config.json\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/.gitattributes s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/.gitattributes\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/tokenization_chatglm.py s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/tokenization_chatglm.py\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/ice_text.model s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/ice_text.model\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/pytorch_model-00007-of-00008.bin s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/pytorch_model-00007-of-00008.bin\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/pytorch_model-00008-of-00008.bin s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/pytorch_model-00008-of-00008.bin\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/pytorch_model-00004-of-00008.bin s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/pytorch_model-00004-of-00008.bin\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/pytorch_model-00005-of-00008.bin s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/pytorch_model-00005-of-00008.bin\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/pytorch_model-00002-of-00008.bin s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/pytorch_model-00002-of-00008.bin\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/pytorch_model-00001-of-00008.bin s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/pytorch_model-00001-of-00008.bin\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/pytorch_model-00006-of-00008.bin s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/pytorch_model-00006-of-00008.bin\n",
      "cp model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/pytorch_model-00003-of-00008.bin s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/pytorch_model-00003-of-00008.bin\n"
     ]
    }
   ],
   "source": [
    "#using s5cmd util to fast upload model to s3\n",
    "! ./ptuning/s5cmd sync ./model/models--THUDM--chatglm-6b/snapshots/4d0fc39a58dcb747ab74ab2c4587bd66dcfa7e74/ s3://sagemaker-us-west-2-687912291502/llm/model/chatglm/orignal/\n",
    "#!rm -rf model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cbcac2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### chatglm 官方P-tuning v2方式（单机单卡）\n",
    "1:安装依赖lib   \n",
    "2:准备数据集(本例以ADGEN 文本生成数据集为例，将解压后的 AdvertiseGen 目录放到本目录  \n",
    "3:修改并bash运行 train.sh  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b07fa0a4-8e21-4441-a9b4-3a038f6c5cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into './tmp'...\n",
      "remote: Enumerating objects: 1094, done.\u001b[K\n",
      "remote: Counting objects: 100% (530/530), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 1094 (delta 478), reused 473 (delta 457), pack-reused 564\u001b[K\n",
      "Receiving objects: 100% (1094/1094), 7.91 MiB | 14.64 MiB/s, done.\n",
      "Resolving deltas: 100% (647/647), done.\n"
     ]
    }
   ],
   "source": [
    "#!pip install rouge_chinese nltk jieba datasets\n",
    "!git clone https://github.com/THUDM/ChatGLM-6B.git ./tmp/\n",
    "#!pip install -r ChatGLM-6B/requirements.txt\n",
    "!cp ChatGLM-6B/requirements.txt ChatGLM-6B/ptuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca76f3d-e961-4c4c-84cc-6ea297711a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!cd ChatGLM-6B/ptuning/ && wget \"https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1\"\n",
    "#!cd ChatGLM-6B/ptuning/ && mv \"index.html?dl=1\" dataset.tar.gz\n",
    "#!cd ChatGLM-6B/ptuning/ && tar -xvf dataset.tar.gz\n",
    "!./ChatGLM-6B/ptuning/s5cmd sync ChatGLM-6B/ptuning/AdvertiseGen/ s3://{bucket}/llm/chatglm/datasets/ \n",
    "#!rm -rf cd ChatGLM-6B/ptuning/dataset.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9e0f9-e025-4529-aadf-2f9d798b018b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define Training Job Name \n",
    "import time\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "instance_type=\"ml.g4dn.2xlarge\"\n",
    "\n",
    "job_name = f'huggingface-chatglm-simple-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "#define the model s3 path which will store your trained model asset\n",
    "#Note: you should use your real s3 path to configure model_s3_path\n",
    "model_s3_path='s3://{}/llm/models/chatglm/simple/'.format(sagemaker_session.default_bucket())\n",
    "output_dir = '/opt/ml/model/adgen-chatglm-6b-ft'\n",
    "model_name_or_path = 'THUDM/chatglm-6b'\n",
    "\n",
    "\n",
    "instance_count = 1\n",
    "#define the enviroment variables for your scripts.\n",
    "environment = {\n",
    "              'MODEL_S3_PATH'          : model_uri,\n",
    "              'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:32',\n",
    "              #'LD_LIBRARY_PATH'        : '${LD_LIBRARY_PATH}:/opt/conda/lib/',\n",
    "              'TRAIN_DATASET'          : '/opt/ml/input/data/AdvertiseGen/train.json',\n",
    "              'TEST_DATASET'           : '/opt/ml/input/data/AdvertiseGen/dev.json',\n",
    "              'PROMPT_COLUMN'          : 'content',\n",
    "              'RESPONSE_COLUMN'        : 'summary',\n",
    "              'MODEL_NAME_OR_PATH'     : model_name_or_path,\n",
    "              'OUTPUT_DIR'             : output_dir,\n",
    "              'MODEL_OUTPUT_S3_PATH'   : model_s3_path,\n",
    "              'TRAIN_STEPS'            : '50'\n",
    "}\n",
    "\n",
    "inputs={\n",
    "   'AdvertiseGen': f\"s3://{bucket}/llm/chatglm/datasets/\"\n",
    "}\n",
    "\n",
    "\n",
    "# create the Estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'start_simple.py',          # user endpoint script\n",
    "    source_dir           = './ptuning',               # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type, # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,           # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    script_mode          = True,\n",
    "    transformers_version = '4.26',            # the transformers version used in the training job\n",
    "    pytorch_version      = '1.13',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py39',            # the python version used in the training job\n",
    "    environment = environment\n",
    ")\n",
    "\n",
    "huggingface_estimator.fit(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d799c69-96b4-4f7e-8f8a-df387f431106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e7992f-e414-40a0-9883-4d3dd1b6ea73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 ls s3://sagemaker-us-west-2-687912291502/huggingface-chatglm-simple-2023-05-06-1-2023-05-06-14-24-12-728/output/model.tar.gz --recursive --human-readable --summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a09a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For local test only\n",
    "!cd ./ptuning/&& bash train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130efd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### chatglm 官方deepspeed方式（全参数的Finetune,单机多卡）\n",
    "1: 准备deepspeed lib，并修改deepspeed.json    \n",
    "2：数据集（以上一致）  \n",
    "3：entrypoint start-single-node.py,设置num-gpus  \n",
    "4：触发bash ds_train_finetune_single_node.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a48210-48ff-4840-a9a0-c8d0e7085adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processes_per_host is set to: 8\n"
     ]
    }
   ],
   "source": [
    "instance_type = 'ml.g5.48xlarge'\n",
    "if instance_type in [\n",
    "    \"ml.p3.16xlarge\",\n",
    "    \"ml.p3dn.24xlarge\",\n",
    "    \"ml.g5.48xlarge\",\n",
    "    \"ml.p4d.24xlarge\"    \n",
    "]:\n",
    "    processes_per_host = 8\n",
    "elif instance_type == \"ml.p2.16xlarge\":\n",
    "    processes_per_host = 16\n",
    "elif instance_type == \"ml.g4dn.2xlarge\":\n",
    "    processes_per_host = 1\n",
    "else:\n",
    "    processes_per_host = 4\n",
    "    \n",
    "\n",
    "print(\"processes_per_host is set to:\", processes_per_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f648f6-7a86-4d18-a087-37401bdd2188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-chatglm-deepspeed-2023-05-1-2023-05-11-09-58-06-102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-05-11 09:58:08 Starting - Starting the training job."
     ]
    }
   ],
   "source": [
    "# define Training Job Name \n",
    "job_name = f'huggingface-chatglm-deepspeed-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "#define the model s3 path which will store your trained model asset\n",
    "#Note: you should use your real s3 path to configure model_s3_path\n",
    "model_s3_path='s3://{}/llm/models/chatglm/deepspeed-single-node/'.format(sagemaker_session.default_bucket())\n",
    "output_dir = '/tmp/model/adgen-chatglm-6b-ft'\n",
    "model_name_or_path = 'THUDM/chatglm-6b'\n",
    "#model_name_or_path = \"/tmp/chatglm/\"\n",
    "\n",
    "\n",
    "instance_count = 1\n",
    "#define the enviroment variables for your scripts.\n",
    "environment = {\n",
    "              \n",
    "              'MODEL_S3_PATH'          : model_uri,\n",
    "              'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:32',\n",
    "              #'LD_LIBRARY_PATH'        : '${LD_LIBRARY_PATH}:/opt/conda/lib/',\n",
    "              'NUM_GPUS'               : str(processes_per_host),\n",
    "              'TRAIN_DATASET'          : '/opt/ml/input/data/AdvertiseGen/train.json',\n",
    "              'TEST_DATASET'           : '/opt/ml/input/data/AdvertiseGen/dev.json',\n",
    "              'PROMPT_COLUMN'          : 'content',\n",
    "              'RESPONSE_COLUMN'        : 'summary',\n",
    "              'MODEL_NAME_OR_PATH'     : model_name_or_path,\n",
    "              'OUTPUT_DIR'             : output_dir,\n",
    "              'MODEL_OUTPUT_S3_PATH'   : model_s3_path,\n",
    "              'TRAIN_STEPS'            :'20'\n",
    "}\n",
    "\n",
    "inputs={\n",
    "   'AdvertiseGen': f\"s3://{bucket}/llm/chatglm/datasets/\"\n",
    "}\n",
    "\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'start-single-node.py',          # user endpoint script\n",
    "    source_dir           = './ptuning',               # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type, # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    script_mode          = True,\n",
    "    transformers_version = '4.26',            # the transformers version used in the training job\n",
    "    pytorch_version      = '1.13',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py39',            # the python version used in the training job\n",
    "    environment = environment,\n",
    ")\n",
    "huggingface_estimator.fit(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed43d3-3727-421d-8a5f-d289dcdd2f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 ls s3://sagemaker-us-west-2-687912291502/llm/models/chatglm/deepspeed-single-node/adgen-chatglm-6b-ft/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf58dcd-d9f2-43b8-b9b7-f477985fb823",
   "metadata": {
    "tags": []
   },
   "source": [
    "### chatglm deepspeed 多机多卡改造\n",
    "1: 准备deepspeed lib，并修改deepspeed.json    \n",
    "2：数据集（以上一致）  \n",
    "3：entrypoint start.py,设置torch distribute launch configure  \n",
    "4：触发bash ds_train_finetune.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea32b09-7afd-42f1-b144-721db4660e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define Training Job Name \n",
    "job_name = f'huggingface-chatglm-deepspeed-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "#define the model s3 path which will store your trained model asset\n",
    "#Note: you should use your real s3 path to configure model_s3_path\n",
    "model_s3_path='s3://{}/llm/models/chatglm/deepspeed-mutip-nodes/'.format(sagemaker_session.default_bucket())\n",
    "output_dir = '/tmp/model/adgen-chatglm-6b-ft'\n",
    "model_name_or_path = 'THUDM/chatglm-6b'\n",
    "\n",
    "\n",
    "instance_count = 2\n",
    "#define the enviroment variables for your scripts.\n",
    "environment = {\n",
    "              'NODE_NUMBER'            : str(instance_count),\n",
    "              'MODEL_S3_PATH'          : model_uri,\n",
    "              'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:32',\n",
    "              #'LD_LIBRARY_PATH'        : '${LD_LIBRARY_PATH}:/opt/conda/lib/',\n",
    "              'NUM_GPUS'               : str(processes_per_host),\n",
    "              'TRAIN_DATASET'          : '/opt/ml/input/data/AdvertiseGen/train.json',\n",
    "              'TEST_DATASET'           : '/opt/ml/input/data/AdvertiseGen/dev.json',\n",
    "              'PROMPT_COLUMN'          : 'content',\n",
    "              'RESPONSE_COLUMN'        : 'summary',\n",
    "              'MODEL_NAME_OR_PATH'     : model_name_or_path,\n",
    "              'OUTPUT_DIR'             : output_dir,\n",
    "              'MODEL_OUTPUT_S3_PATH'   : model_s3_path,\n",
    "              'TRAIN_STEPS'            :'50'\n",
    "}\n",
    "\n",
    "inputs={\n",
    "   'AdvertiseGen': f\"s3://{bucket}/llm/chatglm/datasets/\"\n",
    "}\n",
    "\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'start.py',          # user endpoint script\n",
    "    source_dir           = './ptuning',               # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type, # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    script_mode          = True,\n",
    "    transformers_version = '4.26',            # the transformers version used in the training job\n",
    "    pytorch_version      = '1.13',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py39',            # the python version used in the training job\n",
    "    environment = environment,\n",
    ")\n",
    "huggingface_estimator.fit(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec49d8f8-0c83-4c1d-af1b-42a2df6c2f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!aws s3 rm s3://sagemaker-us-west-2-687912291502/llm/models/chatglm/deepspeed/adgen-chatglm-6b-ft/checkpoint-50 --recursive\n",
    "!aws s3 ls s3://sagemaker-us-west-2-687912291502/llm/models/chatglm/deepspeed-mutip-nodes/adgen-chatglm-6b-ft/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37933c32-ad7c-4564-a8d1-dcfd79531338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##for local test only\n",
    "!cd ./ChatGLM-6B/ptuning/ && bash ./ds_train_finetune.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "008b7a15-0eb5-4a60-803e-132687cb5156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE chatglm/\n",
      "                           PRE model/\n",
      "                           PRE models/\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://sagemaker-us-west-2-687912291502/llm/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
